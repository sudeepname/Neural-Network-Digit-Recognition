{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Downloads/train.csv')\n",
    "test = pd.read_csv('Downloads/test.csv')\n",
    "image0 = train.iloc[0,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image0 = image0.values.reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e033bcef0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = (train.iloc[:,1:].values).astype(\"float\")\n",
    "y_train = (train.iloc[:,0].values).astype(\"int\")\n",
    "x_test = test.values.astype(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0],28,28,1)\n",
    "x_test = x_test.reshape(x_test.shape[0],28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.optimizers import Adam ,RMSprop\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import  backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense , Dropout , Lambda, Flatten,Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_px = x_train.mean().astype(np.float32)\n",
    "std_px = x_train.std().astype(np.float32)\n",
    "\n",
    "def standardize(x): \n",
    "    return (x-mean_px)/std_px "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model1=Sequential()\n",
    "model1.add(Lambda(standardize,input_shape=(28,28,1)))\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(10,activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deep neural network works good on large dataset but as in here there is samll amout of data relativel wats required for a neural net\n",
    "#we will usebelow DataGenerator which generate image of different rotation and size hence multiply the data.\n",
    "gen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x_train\n",
    "y = y_train\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.10, random_state=42)\n",
    "batches = gen.flow(x_train, y_train, batch_size=64)\n",
    "val_batches=gen.flow(x_val, y_val, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer=RMSprop(lr=0.001),\n",
    " loss='categorical_crossentropy',\n",
    " metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/6\n",
      "37800/37800 [==============================] - 113s 3ms/step - loss: 0.2398 - acc: 0.9342 - val_loss: 0.3295 - val_acc: 0.9121\n",
      "Epoch 2/6\n",
      "37800/37800 [==============================] - 111s 3ms/step - loss: 0.2157 - acc: 0.9418 - val_loss: 0.3477 - val_acc: 0.9128\n",
      "Epoch 3/6\n",
      "37800/37800 [==============================] - 133s 4ms/step - loss: 0.2099 - acc: 0.9437 - val_loss: 0.3674 - val_acc: 0.9077\n",
      "Epoch 4/6\n",
      "37800/37800 [==============================] - 187s 5ms/step - loss: 0.2067 - acc: 0.9448 - val_loss: 0.3801 - val_acc: 0.9050\n",
      "Epoch 5/6\n",
      "37800/37800 [==============================] - 184s 5ms/step - loss: 0.2046 - acc: 0.9458 - val_loss: 0.3998 - val_acc: 0.9057\n",
      "Epoch 6/6\n",
      "37800/37800 [==============================] - 185s 5ms/step - loss: 0.2032 - acc: 0.9463 - val_loss: 0.4050 - val_acc: 0.9032\n"
     ]
    }
   ],
   "source": [
    "history1 = model1.fit_generator(generator = batches , steps_per_epoch = batches.n, epochs = 6, validation_data = val_batches,\n",
    "                               validation_steps = val_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here i have added one more layer to improve the accuracy\n",
    "model=Sequential()\n",
    "model.add(Lambda(standardize,input_shape=(28,28,1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64,activation = 'relu'))\n",
    "model.add(Dense(10,activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=RMSprop(lr=0.001),\n",
    " loss='categorical_crossentropy',\n",
    " metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "37800/37800 [==============================] - 139s 4ms/step - loss: 0.0207 - acc: 0.9938 - val_loss: 0.2310 - val_acc: 0.9726\n",
      "Epoch 2/6\n",
      "37800/37800 [==============================] - 141s 4ms/step - loss: 0.0010 - acc: 0.9999 - val_loss: 0.2851 - val_acc: 0.9743\n",
      "Epoch 3/6\n",
      "37800/37800 [==============================] - 157s 4ms/step - loss: 8.5959e-04 - acc: 0.9999 - val_loss: 0.2848 - val_acc: 0.9745\n",
      "Epoch 4/6\n",
      "37800/37800 [==============================] - 256s 7ms/step - loss: 8.5293e-04 - acc: 0.9999 - val_loss: 0.2844 - val_acc: 0.9745\n",
      "Epoch 5/6\n",
      "37800/37800 [==============================] - 275s 7ms/step - loss: 8.5959e-04 - acc: 0.9999 - val_loss: 0.2843 - val_acc: 0.9745\n",
      "Epoch 6/6\n",
      "37800/37800 [==============================] - 242s 6ms/step - loss: 8.4627e-04 - acc: 0.9999 - val_loss: 0.2846 - val_acc: 0.9745\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(generator = batches , steps_per_epoch = batches.n, epochs = 6, validation_data = val_batches,\n",
    "                               validation_steps = val_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(x_test, verbose=0)\n",
    "\n",
    "submissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n",
    "                         \"Label\": predictions})\n",
    "submissions.to_csv(\"Downloads/DigiReco.csv\", index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
